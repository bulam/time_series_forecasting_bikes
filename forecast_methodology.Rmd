---
title: "Time Series Forecasting in R for Business: A Comparison of Models"
output: pdf_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# load necessary packages
library(ggplot2)
library(forecast)
library(lubridate)
suppressMessages(library(memisc, warn.conflicts = FALSE, quietly=TRUE))

```

## 1.Introduction

This guide details the methodology and R code that can be used to evaluate the performance of a time series model and then use the model to forecast a time series. As an example, we use a transportation dataset, but the methdology can be used for any other dataset. The dataset consists of data collected on daily car traffic passing through the Sion-Lausanne tunnel in Switzerland from 2002-01-01 through	2006-02-10^[This dataset was made available through the T-Competition, a forecasting competition on transporation data. The dataset is available here http://forecastingprinciples.com/index.php/data]. 

In this forecasting exercise, our main goal will be to predict the car traffic for the remainder of 2006 and then calculate the year over year change in car traffic relative to 2005.

```{r, out.width = "450px", echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
knitr::include_graphics("tunnel.jpg")
```

To accomplish this, we first split our dataset into training and test datasets. Then, we build a number of forecasting models (TBATS, ARIMA, Neural Networks) using the training dataset and compare their performances against the test dataset. We show that the TBATS^[TBATS, short for Trigonometric Box-Cox transform, ARMA errors, Trend, and Seasonal components. For more information: Forecasting time series with complex seasonal patterns using exponential smoothing; Alysha M De Livera, Rob J Hyndman and Ralph D Snyder] model had the highest degree of accuracy. We then make a forecast using the TBATS model of car traffic to pass through the tunnel in the remainder of year 2006, and calculate the forecasted year over year change in car traffic.

All forecasts in this exercise are implemented using the 'forecast' package in R.

## Forecasting Steps

### 2.1 Dataset Preparation

```{r load_data, echo=FALSE, message=FALSE, warning=FALSE} 
suppressMessages(library(memisc, warn.conflicts = FALSE, quietly=TRUE))

## read in data
data <- read.csv('sion_lausanne_cars_full.csv')

## Load into dataframe
df = data.frame(data, stringsAsFactors = FALSE) 
```

First, we plot below the car traffic data to check for any obvious trends, seasonality patterns and any possible problems with the dataset. The data appears to show both annual and weekly level seasonalities, with big annual spikes during the summer months and periods of lower traffic during the winter months. There do not appear to be obvious trends, but it does appear that traffic had been gradually increasing since 2002, but then stabilized and showed a very slight decline in year 2005. 

Furthermore, we observe that there an anomalous event in June 2002. This could have been caused by a data collection issue or a real-life event like a tunnel closure. In any case, the anomalous event would unnecessarily decrease the accuracy of our forecasts. The missing data can be dealt with in various ways. Here, for the sake of efficiency we simply adjust our data to use only data from after the anomalous incident to build our models. This still leaves use with over 3.5 years worth of data, which is more than sufficient to build a statistical model and perform model testing. 

```{r plot_1, echo=FALSE, message=FALSE, warning=FALSE}
suppressMessages(library(memisc, warn.conflicts = FALSE, quietly=TRUE))

## create an msts object to be used by the forecasting model
msts_cars <- msts(df['cars'], start = decimal_date(as.Date("2002-01-01")), seasonal.periods = c(7,365.25))

# plot to get a sense of trends and seasonality
plot(msts_cars, ylab = "Cars by Date", xlab='', mgp = c(2, 1, 0), cex.main=1, cex.lab=0.8)
title("Historical Bidirectional Car Traffic Through The Sion-Lausanne Tunnel", line = 0.8, cex.main=1)

```

### 2.2 Model Training and Validation
To identify the best performing model, data from the latest full year (2005-02-11 to 2006-02-10) is excluded from model training as a hold-out set. The data for 2002-07-01 to 2005-02-10 is used to train three different time series prediction models -- TBATS, ARIMA and Neural Networks -- and the models are used to make predictions for 2005-02-11 to 2006-02-10. The chart below shows the predictions made by each model for that time period.

```{r model_training, echo=FALSE, message=FALSE, warning=FALSE}
suppressMessages(library(memisc, warn.conflicts = FALSE, quietly=TRUE))

# prepare training dataset, excluding pre-July 2002 data due data anomaly
cars_train <- window(msts_cars, start = decimal_date(as.Date("2002-07-01")), end = decimal_date(as.Date("2005-02-10")))

# prepare hold-out set to validate the models against
cars_holdout <- window(msts_cars, start = decimal_date(as.Date("2005-02-11")), end = decimal_date(as.Date("2006-02-10")))

## try a TBATS model, typically used for time series data with multiple seasonality trends, 
## in our case both annual and weekly seasonalities
fit_tbats <- tbats(cars_train)
fc_tbats <- forecast(fit_tbats, h=365)

## try an ARIMA model
fit_arima <- auto.arima(cars_train)
fc_arima <- forecast(fit_arima, h=365)

## try a neural network model
set.seed(42)
fit_nnetar <- nnetar(cars_train)
fc_nnetar <- forecast(fit_nnetar, h=365)
```

```{r plot_2, echo=FALSE, message=FALSE, warning=FALSE}
suppressMessages(library(memisc, warn.conflicts = FALSE, quietly=TRUE))

# build plots comparing models
mat <- matrix(c(1,2,3), 3)
par(mar=c(2.5, 2.5, 2.0, 1.0), oma=c(2,2,2,2), mgp = c(0, 1, 0))
layout(mat, c(1), c(4,4,4))
par(mar=c(1.5, 2.5, 2.0, 0))
plot(fc_nnetar, main = "Neural Networks", cex.main =1.1) 
par(mar=c(1.5, 2.5, 2.0, 0))
plot(fc_arima, main = "ARIMA", cex.main=1.1)
par(mar=c(1.5, 2.5, 2.0, 0))
plot(fc_tbats, main = "TBATS", cex.main=1.1)
title(main = "Car Traffic per Day Forecasts by Model", ylab = "Car Traffic per Day", font.lab=2, outer = TRUE)

```

The Neural Network and TBATS models appear to have captured the overall growth trend and seasonality well. In addition, the TBATS model is showing relatively small confidence intervals, indicating high confidence in its predictions. The ARIMA model appears to have less accuracy and provides very broad confidence intervals. 

To compare the accuracy of each model, we calculate the Mean Average Percentage Error (MAPE), Mean Average Error (MAE), and the Root Mean Squared Error (RMSE) to measure how much the predictions for the past year from each model diverged from the actual hold-out dataset. The 'forecast' package in R contains an accuracy function that will calculate various error metrics automatically. Here we calculate the error metrics manually for illustration purposes.

``` {r us_model_comparison, echo=FALSE, message=FALSE, warning=FALSE}
suppressMessages(library(memisc, warn.conflicts = FALSE, quietly=TRUE))
# put predictions in dataframes
tbats_preds <- data.frame(fc_tbats)['Point.Forecast']
arima_preds <- data.frame(fc_arima)['Point.Forecast']
nnetar_preds <- data.frame(fc_nnetar)['Point.Forecast']

# create a dataframe with all predictions
preds_all <- cbind(data.frame(cars_holdout), tbats_preds, arima_preds, nnetar_preds)

# rename columns with names of each model
names(preds_all)[2] <- "tbats_preds"
names(preds_all)[3] <- "arima_preds"
names(preds_all)[4] <- "nnetar_preds"



# Comparing models

# defining MAPE formula
mape <- function(arg1, arg2){
  mape = mean(abs((arg1 / arg2)-1)^1)*100
  return(mape)
}

mape_tbats <- round(mape(preds_all['cars'], preds_all['tbats_preds']), 2)
mape_arima <- round(mape(preds_all['cars'], preds_all['arima_preds']), 2)
mape_nnetar <- round(mape(preds_all['cars'], preds_all['nnetar_preds']), 2) 

mape_errors <- cbind(mape_tbats, mape_arima, mape_nnetar)
colnames(mape_errors) <- c("tbats","arima","nnetar")

# MAE: Mean Absolute Error

# defining MAE formula
mae <- function(arg1, arg2){
  mae = mean(abs(arg1 - arg2)^1)
  return(mae)
}

# calculate RMSEs off point forecasts
mae_tbats <- mae(preds_all['cars'], preds_all['tbats_preds'])
mae_arima <- mae(preds_all['cars'], preds_all['arima_preds'])
mae_nnetar <- mae(preds_all['cars'], preds_all['nnetar_preds'])

mae_errors <- cbind(mae_tbats, mae_arima, mae_nnetar)
colnames(mae_errors) <- c("tbats","arima","nnetar")


# RMSE: root-mean-square error

# defining RMSE formula
rmse <- function(arg1, arg2){
  rmse = sqrt(mean((arg1 - arg2)^2))
  return(rmse)
}

# calculate RMSEs off point forecasts
rmse_tbats <- rmse(preds_all['cars'], preds_all['tbats_preds'])
rmse_arima <- rmse(preds_all['cars'], preds_all['arima_preds'])
rmse_nnetar <- rmse(preds_all['cars'], preds_all['nnetar_preds'])

rmse_errors <- cbind(rmse_tbats, rmse_arima, rmse_nnetar)
colnames(rmse_errors) <- c("tbats","arima","nnetar")

percent_custom <- function(x, digits = 2, format = "f", ...) {
  paste0(formatC(100 * x, format = format, digits = digits, ...), "%")
}



par(mfrow = c(1,3))
par(pty="s")
bp1 <- barplot(mape_errors, main = "Mean Average Percentage Error", cex.main=1, ylim = c(0, 50))
text(bp1, mape_errors, labels = mape_errors, cex=1, pos=3) 
par(pty="s")
bp2 <- barplot(mae_errors, main = "Mean Average Error", cex.main=1, ylim = c(0, 5000))
text(bp2, mae_errors, labels = round(mae_errors, 1), cex=1, pos=3) 
par(pty="s")
bp3 <- barplot(rmse_errors, main = "Root Mean Squared Error", cex.main=1, cex.axis = 1, ylim = c(0, 6000))
text(bp3, rmse_errors, labels = round(rmse_errors, 1), cex=1, pos=3) 

```

 The MAPE for the TBATS model is $`r I(mape_tbats)`$%. For the ARIMA model, the MAPE is $`r I(mape_arima)`$% and for the neural networks model, the MAPE is $`r I(mape_nnetar)`$%. The TBATS model is the best performing according to all metrics. In addition to its performance, the current implementation of the TBATS model in the forecast package is superior to the Neural Networks model because it offers a model decomposition and Confidence Interval calculation functionalities, as well as deterministic performance.  
 
 The chart below shows the decomposition of the trends and seasonalities detected in the data by the TBATS model. The 'level' trendline shows the overall growth trend, while the season1 and season2 charts show the weekly and annual seasonalities, respectively.

```{r us_plot_3, echo=FALSE, message=FALSE, warning=FALSE}
# tbats model decomposition
par(mfrow = c(1,1), pty="m", cex.main=1)
plot(fit_tbats, cex.main=1, xlab='', mgp = c(2, 1, 0), main = '')
title("Decomposition by TBATS model", line = 1.1, cex.main=1)
```

### 2.3 Predicting Car Traffic For The Rest of 2006

Since the TBATS model showed the highest degree of accuracy and interpretability, it is used to make the forecast for car traffic for the rest of 2006. The TBATS model was retrained on all data (2002-07-01 -- 2006-02-10), and a forecast was made for the remainder of 2006. The chart below shows the forecast. 

```{r us_plot_4, echo=FALSE, message=FALSE, warning=FALSE}

# tbats is the winner, retrain tbats with all data, including past year

par(mfrow=c(1,1))

## retrain tbats with all data
cars_all_train <- window(msts_cars, start = decimal_date(as.Date("2002-07-01")), end = decimal_date(as.Date("2006-02-10")))
fit_tbats_all <- tbats(cars_all_train)
fc_tbats_all <- forecast(fit_tbats_all, h=365)
plot(fc_tbats_all, main='')
title("Seller Acount Creation Forecast, October 1, 2006 - December 31, 2017", line = 0.9, cex.main=1)

# get forecasts column only
cars_forecast <- data.frame(fc_tbats_all)['Point.Forecast']

# replace timepoints with actual dates
cars_forecasts_dates <- seq.Date(as.Date("2006-02-11"), by = 1, length.out = 365)
cars_forecasts_w_dates <- zoo(cars_forecast, cars_forecasts_dates)

# get forecasts for the remainder of 2006 only
cars_forecasts_remainder_2006 <- window(cars_forecasts_w_dates, start = '2006-02-11', end = '2006-12-31')
cars_forecasts_remainder_2006_sum <- as.integer(sum(cars_forecasts_remainder_2006))
cars_forecasts_remainder_2006_sum_print <- formatC(as.integer(sum(cars_forecasts_remainder_2006)), format="d", big.mark=',')


# get sign ups so far
cars_2006_so_far <- window(msts_cars, start = decimal_date(as.Date("2006-01-01")), end = decimal_date(as.Date("2006-02-10")))

# get total car traffic in 2006, actual so far + forecasted
all_cars_2006_sum <- as.integer(sum(cars_2006_so_far) + as.integer(sum(cars_forecasts_remainder_2006)))
all_cars_2006_sum_print <- formatC(all_cars_2006_sum, format="d", big.mark=',')

# get car traffic in 2005
traffic_2005 <- window(msts_cars, start = decimal_date(as.Date("2005-01-01")), end = decimal_date(as.Date("2005-12-31")))

traffic_2005_sum <- as.integer(sum(traffic_2005)) 

# projected yoy decline in car traffic
diff_yoy <- round(((all_cars_2006_sum / traffic_2005_sum) - 1) * 100, 2)
```

The model predicts that $`r I(cars_forecasts_remainder_2006_sum_print)`$ cars will pass through the Sion-Lausanne tunnel in the remainder of 2006, making for a total of $`r I(all_cars_2006_sum_print)`$ cars passing through the tunnel in 2006. In 2005, $`r I(traffic_2005_sum)`$ cars passed through the tunnel, meaning that the number of cars to pass through the Sion-Lausanne tunnel is expected to decrease by $`r I(diff_yoy)`$% in 2006 compared to 2005.

### 3. References

1. [Forecasting time series with complex seasonal patterns using exponential smoothing; Alysha M De Livera, Rob J Hyndman and Ralph D Snyder](http://robjhyndman.com/papers/ComplexSeasonality.pdf)
2. [forecast package in R](https://cran.r-project.org/web/packages/forecast/index.html)
3. Tunnel image credit: https://www.autobahnen.ch/images/pic00823.jpg


### Links
[Github repo link](https://github.com/bulam/time_series_forecasting_cars)
